<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG" />
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG" />
  <meta property="og:url" content="URL OF THE WEBSITE" />
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>TPO</title>
  <link rel="icon" type="image/x-icon" href="static/images/project_icon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">

            <!-- Title -->
            <h1 class="title is-1 publication-title">A Topic-level Self-Correctional Approach to Mitigate Hallucinations in MLLMs</h1>
            
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="" target="_blank">Lehan He</a><sup>*1,2,3</sup>
              </span>,
              <span class="author-block">
                <a href="" target="_blank">Zeren Chen</a><sup>*1,2</sup>
              </span>,
              <span class="author-block">
                <a href="" target="_blank">Zhelun Shi</a><sup>1,2</sup>
              </span>,
              <span class="author-block">
                <a href="" target="_blank">Tianyu Yu</a><sup>4</sup>
              </span>
              <br>
              <span class="author-block">
                <a href="" target="_blank">Jing Shao</a><sup>â€ 1</sup>
              </span>,
              <span class="author-block">
                <a href="" target="_blank">Lu Sheng</a><sup>â€ 2</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <sup>1</sup>Shanghai AI Laboratory
                ,
                <sup>2</sup>School of Software, Beihang University
                <br>
                <sup>3</sup>Shanghai Innovation Institute
                ,
                <sup>4</sup>Tsinghua University
              </span>
              <span class="eql-cntrb">
                <small>
                  <br>
                  <sup>*</sup>Indicates Equal Contribution
                  ,
                  <sup>â€ </sup>Corresponding authors
                </small>
              </span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">

                <!-- Arxiv PDF link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2411.17265" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>

                <!-- Github link -->
                <span class="link-block">
                  <a href="" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                
                <!-- Dataset link -->
                <span class="link-block">
                  <a href="" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-database"></i>
                    </span>
                    <span>Dataset</span>
                  </a>
                </span>

                <!-- Model link -->
                <span class="link-block">
                  <a href="" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-comment"></i>
                    </span>
                    <span>Model</span>
                  </a>
                </span>

              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- project introduce -->
  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
      <font size="5">
        <div class="has-text-centered">
          <p>ðŸ”¥<b>What's New</b></p>
        </div>
      </font>
      <font size="4">
        <table width="75%" align="center" border="1" cellspacing="0" cellpadding="10"><tbody>
          <tr>
            <td>
              <div style="height: 55px; overflow: auto;">
                <ul style="list-style-type: none; padding: 0;">
                  <li style="display: inline-block; width: 100%;"> <span style="font-family: monospace;">[2024.11.27]</span> ðŸš€ We released the ArXiv paper.</li>
                  <li style="display: inline-block; width: 100%;"> <span style="font-family: monospace;">[2024.12.XX]</span> ðŸš€ Code, model and data will be released soon.</li>
                </ul>
              </div>
            </td>
          </tr>
        </tbody>
      </table>
    </font>
    </div>
  </section>

  <!-- project introduce -->
  <section class="hero teaser is-light" id="abstract">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <br>
          <br>
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Aligning the behaviors of Multimodal Large Language Models (MLLMs) with human preferences is crucial for de veloping robust and trustworthy AI systems. 
              While recent attempts have employed human experts or powerful auxil iary AI systems to provide more accurate preference feed back, 
              such as determining the preferable responses from MLLMs or directly rewriting hallucination-free responses, 
              extensive resource overhead compromise the scalability of the feedback collection. 
            </p>
            <p>
              In this work, we introduce Topic level Preference Overwriting (TPO), 
              a self-correctional ap proach that guide the model itself to mitigate its own hallu cination at the topic level. 
              Through a deconfounded strat egy that replaces each topic within the response with the best or worst alternatives generated by the model itself, 
              TPO creates more contrasting pairwise preference feed back, enhancing the feedback quality without human or pro prietary model intervention. 
              Notably, the experimental re sults demonstrate proposed TPO achieves state-of-the-art performance in trustworthiness, significantly reducing the object hallucinations by ~92% and overall hallucinations by ~38%.
            </p>
            <br>
            <br>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End project introduce -->

  
  <!-- method -->
  <section class="hero is-small">
    <div class="hero-body has-text-centered">
      <h2 class="title is-3 mathvista">
        <img src="static/images/project_icon.ico" style="width:1em;vertical-align: middle" alt="Logo"/>
        <span class="mathvista" style="vertical-align: middle">Topic-level Self-Correctional RLAIF</span>
      </h2>
    </div>
    <div class="hero-body">
      <div class="container">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <div class="content has-text-justified">
              <p>
                In this work, we aim to effectively enhance the prefer ence pairs in a self-correctional manner, without human or proprietary MLLM interventions. 
                To this end, we propose a topic-level self-correctional paradigm TPO to reduce hallucination, involving two primary steps: topic clustering and topic overwriting.
              </p>
              <centering>
                <div style="text-align: center;">
                  <img id="teaser" width="100%" src="static/images/motivation.png">     
                </div>
              </centering>
              <br>
              <br>
              <p>
                <strong>The proposed TPO framework:</strong>
              </p>
              <p>
                We collect 21k feedback data by using TPO pipeline to correct or contaminate the model responses.
                The training takes only 1 hour with 8 A100 GPUs to get our TPO-7B model which is initialized from <a href="https://huggingface.co/liuhaotian/llava-v1.5-7b">LLaVA-1.5-7B</a>.
              </p>
              <centering>
                <div style="text-align: center;">
                  <img id="teaser" width="100%" src="static/images/overall_paradigm.png">     
                </div>
              </centering>
              <br>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End method -->


  <!-- performance -->
  <section class="hero is-small">
    <div class="hero-body has-text-centered">
      <h2 class="title is-3 mathvista">
        <span class="mathvista" style="vertical-align: middle">ðŸ“ƒ Performance</span>
      </h2>
    </div>
    <div class="hero-body">
      <div class="container">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <div class="content has-text-justified">
              <p>
                <strong>Applying TPO for preference learning significantly improves the trustworthiness.</strong>
              </p>
              <centering>
                <div style="text-align: center;">
                  <img id="teaser" width="80%" src="static/images/main_result.png">     
                </div>
              </centering>
              <br>
              <br>
              <p>
                <strong>Data-efficient and showing good scaling results:</strong>
              </p>
              <centering>
                <div style="text-align: center;">
                  <img id="teaser" width="60%" src="static/images/data_scale.png">     
                </div>
              </centering>
              <br>
              <br>
              <p>
                <strong>
                  Responses low hallucination rate while being informative:
                </strong>
              </p>
              <centering>
                <div style="text-align: center;">
                  <img id="teaser" width="60%" src="static/images/win_rate.png">     
                </div>
              </centering>
              <br>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End performance -->


  <!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
        @article{he2024topic,
          title={A Topic-level Self-Correctional Approach to Mitigate Hallucinations in MLLMs}, 
          author={Lehan He and Zeren Chen and Zhelun Shi and Tianyu Yu and Jing Shao and Lu Sheng},
          journal={arXiv preprint arXiv:2411.17265},
          year={2024}
        }
      </code></pre>
    </div>
  </section>
  <!--End BibTex citation -->


  <!-- example -->
  <section class="hero is-small">
    <div class="hero-body has-text-centered">
      <h4 class="title is-4 mathvista">
        <span class="mathvista" style="vertical-align: middle">ðŸ–Œ Examples on more Helpful and less Hallucinated Visual Instruction Following</span>
      </h4>
    </div>
    <div class="hero-body">
      <div class="container">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <div class="content has-text-justified">
              <centering>
                <div style="text-align: center;">
                  <img width="100%" src="static/images/case_study.png">
                </div>
              </centering>
              <br>
              <br>
              <strong>Qualitative results of preferred and inferior responses within preference feedback generated by TPO.</strong>
              <br>
              <br>
              <centering>
                <div style="text-align: center;">
                  <img width="75%" src="static/images/more_case_study_data1.png">
                </div>
              </centering>
              <centering>
                <div style="text-align: center;">
                  <img width="75%" src="static/images/more_case_study_data2.png">
                </div>
              </centering>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End example -->


  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">

            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                target="_blank">Academic Project Page Template</a> which was adopted from the 
                <a href="https://nerfies.github.io" target="_blank">
                  Nerfies
                </a> 
                project page, licensed under a 
                <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">
                  Creative Commons Attribution-ShareAlike 4.0 International License
                </a>
            </p>

          </div>
        </div>
      </div>
    </div>
  </footer>


</body>

</html>